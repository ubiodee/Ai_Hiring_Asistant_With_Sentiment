{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM1GiDtQ9qD+fMyOoZZmGeg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ubiodee/Ai_Hiring_Asistant_With_Sentiment/blob/main/Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "from textblob import TextBlob"
      ],
      "metadata": {
        "id": "h4OssPtncXzj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "job_postings = pd.read_csv('/job_postings.csv')"
      ],
      "metadata": {
        "id": "tNqTKF_JchfY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))"
      ],
      "metadata": {
        "id": "nrrvwS9Zc5to"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ">>> import nltk\n",
        ">>> nltk.download(\"stopwords\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNOzAwyfdd8P",
        "outputId": "9311db5e-f17f-4171-acfe-13618d9d7c3f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "Y1_RBOzxfZvN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_text(text):\n",
        "    # Remove non-alphanumeric characters\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "    # Tokenize text into individual words\n",
        "    tokens = word_tokenize(text.lower())\n",
        "    # Remove stop words from tokens\n",
        "    filtered_tokens = [word for word in tokens if word not in stop_words]\n",
        "    # Lemmatize filtered tokens\n",
        "    lemmatized_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
        "    # Return cleaned text as a string\n",
        "    return ' '.join(lemmatized_tokens)"
      ],
      "metadata": {
        "id": "Rvhvo9npfeA4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cqi5D3m_Hnc3",
        "outputId": "95f01cc9-9ee2-442d-a1d6-0433c08ac2dc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "cJMOuIE-H0E7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "job_postings['cleaned_text'] = job_postings['text'].apply(clean_text)"
      ],
      "metadata": {
        "id": "uLvxCdQrfk0R"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ">>> import nltk\n",
        ">>> nltk.download('punkt')\n",
        ">>> nltk.download('wordnet')"
      ],
      "metadata": {
        "id": "c_Mo_s5Cf2Ve",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f356841a-81a5-4a44-9ed6-10d3b267409a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inclusive_keywords = ['equal opportunity', 'diversity', 'inclusion', 'minority', 'gender', 'race', 'ethnicity']"
      ],
      "metadata": {
        "id": "nkMmVCiIJSTL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criteria = {'Gender': ['woman', 'man', 'non-binary', 'transgender', 'genderqueer'],\n",
        "            'Race/Ethnicity': ['Black', 'Hispanic/Latinx', 'Asian', 'White', 'Native American', 'Middle Eastern'],\n",
        "            'Age': ['young', 'old', 'experienced', 'fresh'],\n",
        "            'Disability': ['disabled', 'handicapped', 'wheelchair user', 'able-bodied'],\n",
        "            'LGBTQ+': ['lesbian', 'gay', 'bisexual', 'queer', 'trans', 'non-heterosexual', 'non-cisgender']}\n"
      ],
      "metadata": {
        "id": "Z25nL4h5NzFs"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "scoring = {'Gender': 4,\n",
        "           'Race/Ethnicity': 3,\n",
        "           'Age': 1,\n",
        "           'Disability': 1,\n",
        "           'LGBTQ+': 2}"
      ],
      "metadata": {
        "id": "yzT8y5gwRsbW"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_inclusive_score(description):\n",
        "    # Clean the job description text\n",
        "    cleaned_text = clean_text(description)\n",
        "    # Split cleaned text into individual words\n",
        "    words = cleaned_text.split()\n",
        "    # Calculate total number of words in job posting\n",
        "    total_words = len(words)\n",
        "    # Calculate number of occurrences of each inclusive keyword\n",
        "    keyword_counts = [words.count(keyword.lower()) for keyword in inclusive_keywords]\n",
        "    # Calculate total number of inclusive keywords\n",
        "    total_keywords = sum(keyword_counts)\n",
        "    # Calculate inclusive score as a percentage of total words\n",
        "    inclusive_score = total_keywords / total_words * 100\n",
        "    # Return the inclusive score\n",
        "    return inclusive_score"
      ],
      "metadata": {
        "id": "07wJbz68SIvb"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sentiment_score(description):\n",
        "    # Clean job description text\n",
        "    cleaned_text = clean_text(description)\n",
        "    # Get TextBlob object for cleaned text\n",
        "    blob = TextBlob(cleaned_text)\n",
        "    # Calculate sentiment score using TextBlob\n",
        "    sentiment_score = blob.sentiment.polarity\n",
        "    return sentiment_score"
      ],
      "metadata": {
        "id": "jkM_UJWhSI6y"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "description = input(\"Please enter the job description: \")"
      ],
      "metadata": {
        "id": "O9GRKorTpx1E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "df05c2f7-8690-4d0b-e9c3-366b4f69d5eb"
      },
      "execution_count": 16,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please enter the job description: Do you hate or love me\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inclusive_score = get_inclusive_score(description)\n",
        "sentiment_score = get_sentiment_score(description)\n"
      ],
      "metadata": {
        "id": "M5nj1wKR-DdN"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Inclusive Score: {:.2f}\".format(inclusive_score))\n",
        "print(\"Sentiment Score: {:.2f}\".format(sentiment_score))\n",
        "if inclusive_score < 10:\n",
        "    print(\"Suggestion: Consider adding more diversity words.\")\n",
        "elif inclusive_score >= 10 and inclusive_score < 20:\n",
        "    print(\"Suggestion: Consider adding words that promote inclusion based on sexual orientation.\")\n",
        "else:\n",
        "    print(\"This looks okay and you can post it now.\")\n",
        "if sentiment_score == 0:\n",
        "    print(\"Your Job description is neutral \")\n",
        "else:\n",
        "    print(\"You may consider checking the language of your description\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nn6nVHx41ZPR",
        "outputId": "acaa0bdd-ac40-41c6-e8c1-614fb62f6d87"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Inclusive Score: 0.00\n",
            "Sentiment Score: -0.15\n",
            "Suggestion: Consider adding more diversity words.\n",
            "You may consider checking the language of your description\n"
          ]
        }
      ]
    }
  ]
}